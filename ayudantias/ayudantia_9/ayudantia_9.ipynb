{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes y Clasificación de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ayudantía trabajaremos con el modelo Naive Bayes y aprovecharemos que es muy usado para clasificación de texto para dar una introducción (muy superficial) a cómo pueden trabajar con este tipo de datos.\n",
    "Para esto, trabajaremos con un dataset de SMS que han sido clasificados como Spam o Ham (No Spam). La base fue descargada de: [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "Primero veamos más en detalle el modelo:\n",
    "\n",
    "\n",
    "![Naive Bayes Model](https://afit-r.github.io/public/images/analytics/naive_bayes/naive_bayes_icon.png)\n",
    "\n",
    "El modelo se basa en el teorema de Bayes para estimar la probabilidad de que una observación corresponda a una cierta clase, dadas las características de esa observación.\n",
    "\n",
    "El denominador de la fracción de la derecha en realidad no nos importa, porque nuestro $x$ ya está dado, por lo tanto, es constante, así que nos fijaremos solo en el numerador.\n",
    "\n",
    "La probabilidad a priori de que un observación corresponda a cierta clase $P(c)$, el modelo la estima a partir de la presencia de las clases en nuestro dataset de entrenamiento (aunque esto es un parámetro que se puede entregar por fuera o, simplmente, usar una distribución uniforme).\n",
    "\n",
    "La verosimilitud, $P(x|c)$, el modelo la estima calculando la presencia de cada feature $x$ para cada clase $c$. Por lo tanto, esta es la parte en que el modelo aprende realmente de las features que le entregamos.\n",
    "\n",
    "Vamos con la aplicación práctica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos nuestros datos desde Google Drive\n",
    "import requests\n",
    "url = \"https://drive.google.com/uc?id=13I_Te6decSUBcgzqxwK6qUaFwCtW9nou\"\n",
    "data = requests.get(url)\n",
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestros datos vienen en un solo string, donde cada línea está separada por un new line character (\\n)\n",
    "# Y dentro de cada línea, tenemos primero la etiqueta y luego el mensaje de texto, separados por un tab (\\t)\n",
    "# Usando esta estructura, vamos a procesar nuestros datos y separarlos en dos listas\n",
    "list_txt = data.text.split('\\n')\n",
    "txts = []\n",
    "labels = []\n",
    "for el in list_txt:\n",
    "    splitted = el.split('\\t')\n",
    "    txts.append(splitted[1])\n",
    "    labels.append(splitted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(txts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya teniendo nuestros textos listos para ser trabajados, aquí podríamos aplicar muchas técnicas de preprocesamiento:\n",
    "- Estandarización de palabras (para corregir errores de ortografía, por ejemplo)\n",
    "- Reemplazo de abreviaciones\n",
    "- Identificación de palabras que no nos ayudan a clasificar el texto (por ejemplo, nombres propios)\n",
    "- Etc.\n",
    "\n",
    "Pero como esta es solo una breve introducción al procesamiento de textos, no aplicaremos ninguna de ellas e iremos directo al splitting y preparación de los datos para entregarselos a nuestros modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación en train y test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(txts, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como saben, nuestros modelos siempre esperan features numéricas, por lo tanto no podemos pasarles directamente los textos de nuestro training set.\n",
    "Existen varias técnicas para transformar textos en representaciones numéricas y vamos a ver primero la vectorización por conteo.\n",
    "Lo que vamos a hacer es identificar todas las palabras que están en nuestro training set (corpus) y contaremos las veces que aparecen en cada una de nuestras observaciones para representarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos nuestro vectorizador, lo ajustamos con SOLO el training set y transformamos tanto nuestro training como nuestro test set:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos 7720 palabras distintas en nuestro\n",
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miremos más en detalle cómo se transformó el primer mensaje de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos en qué indices nuestra matriz quedó con valores mayores a 0:\n",
    "ix = np.where(X_train_vec.toarray()[0]>0)\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora veamos qué valores están en esas posiciones\n",
    "X_train_vec.toarray()[0][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos a qué palabras de nuestro universo de palabras corresponden esas posiciones\n",
    "vectorizer.get_feature_names_out()[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a probar dos modelos distintos para comparar sus performances. \n",
    "\n",
    "En realidad, son el mismo modelo de Naive Bayes pero lo que cambia es el kernel que usan.\n",
    "\n",
    "El kernel es la distribución de probabilidad que asume el modelo por detrás para calcular las verosimilitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partiremos con un kernel Gaussiano (Distribución Normal)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_vec.toarray(), y_train).predict(X_test_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al modelo con el kernel Gaussiano le va bastante bien.\n",
    "\n",
    "Probemos ahora con un kernel Multinomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(X_train_vec.toarray(), y_train).predict(X_test_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este modelo le va mucho mejor! Tiene que ver con el kernel que usamos:\n",
    "\n",
    "El kernel Gaussiano es más apropiado para features con valores continuos, mientras que el Multinomial lo es para features discretas, como las que tenemos en nuestro training set.\n",
    "\n",
    "Veamos algunos mensajes en los que se equivocó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    ix = np.where(y_test != y_pred)[0][i]\n",
    "    print(X_test[ix], y_test[ix], y_pred[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos qué pasaría si el modelo no asumiese que hay más mensajes de ham que de spam, es decir, modifiquemos las distribuciones a priori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_uniform = MultinomialNB(fit_prior=False)\n",
    "y_pred = mnb_uniform.fit(X_train_vec.toarray(), y_train).predict(X_test_vec.toarray())\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mnb.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mnb_uniform.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probemos ahora con otro tipo de vectorización: TF-IDF\n",
    "TF-IDF significa Term Frequency times Inverse Document Frequency\n",
    "\n",
    "Term Frequency es simplemente la frecuencia (en porcentaje) de aparición de cada palabra en cada uno de nuestros textos. Entonces, va a ser igual a nuestra vectorización por cuenta, pero cada valor dividido por la cantidad total de palabras en cada texto.\n",
    "\n",
    "Inverse Document Frequency nos va a permitir darle menos peso a las palabras que aparecen en muchos texto. Se calcula como el logaritmo de la división entre el número total de textos y la cantidad de textos donde aparece una palabra en específico.\n",
    "\n",
    "![tf idf](https://qph.cf2.quoracdn.net/main-qimg-60a54c42850675139e2899634d3a669c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos nuestro vectorizador, lo ajustamos y transformamos ambos sets de datos\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_vec = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vec = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo quedaron nuestras features ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos en qué indices nuestra matriz quedó con valores mayores a 0:\n",
    "ix = np.where(X_train_vec.toarray()[10]>0)\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora veamos qué valores están en esas posiciones\n",
    "X_train_vec.toarray()[10][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos a qué palabras de nuestro universo de palabras corresponden esas posiciones\n",
    "tfidf_vectorizer.get_feature_names_out()[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(tfidf_vectorizer.get_feature_names_out()[ix], X_train_vec.toarray()[10][ix])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_vec.toarray(), y_train).predict(X_test_vec.toarray())\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(X_train_vec.toarray(), y_train).predict(X_test_vec.toarray())\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
