{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas e Imputación de Missings y Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas es una librería de Python usada para trabajar con datasets.\n",
    "\n",
    "Usando Pandas podemos analizar, limpiar, explorar y manipular datos de forma muy fácil.\n",
    "\n",
    "##### ¿Qué es una librería?\n",
    "\n",
    "Una librería es una colección de funciones y métodos que nos permiten realizar muchas acciones usando código que ya fue escrito (probablemte por alguien más).\n",
    "\n",
    "##### ¿Cómo usar las funciones de Pandas?\n",
    "\n",
    "Si están trabajando en Colab, Pandas viene instalado por defecto, por lo que basta con importar la librería como en la celda siguiente (noten que usamos el alias ```pd``` para referirnos a la librería):\n",
    "\n",
    "(Si están trabajando en su propio ambiente, instálenla usando ```!pip install pandas```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Qué estructuras de datos nos provee Pandas?\n",
    "\n",
    "Pandas nos provee de dos estructuras de datos:\n",
    "- Series: Una Serie es un conjunto de datos unidimensional (de cualquier tipo), cada uno asociado a un índice único. Es como una columna dentro de una tabla. \n",
    "\n",
    "- DataFrame: Un DataFrame es un conjunto datos bidimensional (de cualquier tipo). Es como una tabla con filas y columnas (o un conjunto de varias Series).\n",
    "\n",
    "Podemos crear Series y DataFrames a partir de Listas o Diccionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = ['a', 'b', 'c', 'd', 'e']\n",
    "numeros = [1, 2, 3, 4, 5]\n",
    "my_1d_dict = {letra: numero for letra, numero in zip(letras, numeros)}\n",
    "\n",
    "print('Nuestro diccionario:', my_1d_dict)\n",
    "\n",
    "series_from_list = pd.Series(letras)\n",
    "print(\"Nuestra serie a partir de una lista:\\n\", series_from_list)\n",
    "\n",
    "series_from_dict = pd.Series(my_1d_dict)\n",
    "print(\"Nuestra serie a partir de un diccionario:\\n\", series_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = ['a', 'b', 'c', 'd', 'e']\n",
    "numeros = [1, 2, 3, 4, 5]\n",
    "my_dict = {'letras': letras, 'numeros': numeros}\n",
    "\n",
    "print('Nuestro diccionario:', my_dict)\n",
    "\n",
    "df_from_lists = pd.DataFrame(zip(letras, numeros), columns = ['letras', 'numeros'])\n",
    "print(\"Nuestro DataFrame a partir de listas:\\n\", df_from_lists)\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(my_dict, orient='columns')\n",
    "print(\"Nuestro DataFrame a partir de un diccionario:\\n\", df_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importar datos\n",
    "\n",
    "Pandas nos permite importar fácilmente distintos tipos de archivos de datos como excel, csv, parquet, json, etc. También puede leer datos directamente desde un servidor SQL.\n",
    "\n",
    "Para esta ayudantía vamos a trabajar con un dataset de tipos de cambio de distintas monedas respecto al dólar. Los datos originales los pueden en contrar en https://si3.bcentral.cl/Siete/ES/Siete/Cuadro/CAP_TIPO_CAMBIO/MN_TIPO_CAMBIO4/TCB_510_PARIDADES/TCB_510. Se les hicieron algunas modificaciones para fines pedagógicos.\n",
    "\n",
    "Vamos a leer el archivo directamente desde Drive en formato .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=18CFi-KxkVe0VRrg4awCXE0585GHRvvx4\"\n",
    "df = pd.read_csv(url)\n",
    "df.head() # Ocupamos el método head para ver las primeras lineas del DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primera mirada al dataset\n",
    "\n",
    "Pandas tiene algunos métodos y propiedades que nos van a ayudar de forma fácil a tener una idea rápida de con qué datos estamos trabajando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué forma tienen nuestros datos?\n",
    "print(df.shape) #Número de Filas, Número de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué columnas tiene nuestro dataset?\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué tipo de datos corresponde a cada columna y cuántos valores no vacíos hay?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las columnas numéricas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Acceso a datos\n",
    "\n",
    "Para acceder a ciertos datos específicos de un DataFrame tenemos dos opciones para hacerlo:\n",
    "\n",
    "- Acceso por etiqueta (o nombre de la columna/fila): Para esto ocupamos el método ```.loc[x,y]``` de nuestro DataFrame, donde ```x``` va a representar los nombres de las filas a las que queremos acceder (el nombre del índice asociado a cada fila) e ```y``` va a representar los nombres de las columnas a las que queremos acceder.\n",
    "\n",
    "- Acceso por posición: Para esto ocupamos el método ```.iloc[x,y]``` de nuestro DataFrame, donde ```x``` va a representar la posición (recuerden que parten desde 0!) de las filas a las que queremos acceder e ```y``` va a representar laa posición de las columnas a las que queremos acceder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: acceder a la cuarta fila de la columna CLP/USD\n",
    "# Por etiqueta\n",
    "print(df.loc[3, 'CLP/USD'])\n",
    "print(df.iloc[3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Acceder a las primeras 5 filas de la columna ARS/USD\n",
    "print(df.loc[:5, 'ARS/USD'])\n",
    "print(df.iloc[:5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quieren acceder a una columna completa, pueden simplemente usar el nombre de la columna entre [], sin usar ningún método\n",
    "print(df['EUR/USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuando quieran acceder a más de una columna, deben entregar entre los [] una lista con los nombres\n",
    "print(df[['CLP/USD', 'PEN/USD']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtros\n",
    "\n",
    "Pandas nos permite acceder a columnas o filas basado en filtros que queramos aplicar. \n",
    "\n",
    "Para esto tenemos que usar los operadores lógicos que aprendimos en la primera ayudantía, con la salvedad de que ```and``` se debe reemplazar por ```&``` y ```or``` por ```|```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a todas las filas en que el tipo de cambio CLP/USD fue menor a 470\n",
    "df[df['CLP/USD'] < 470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a todas las filas en que el tipo de cambio CLP/USD fue menor a 500 y el tipo de cambio ARS/USD fue menor a 4\n",
    "df[(df['CLP/USD'] < 500) & (df['ARS/USD'] < 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a todas las filas en que el tipo de cambio CLP/USD fue menor a 480 o el tipo de cambio ARS/USD fue mayor a 500\n",
    "df[(df['CLP/USD'] < 480) | (df['ARS/USD'] > 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creación de columnas\n",
    "\n",
    "Para crear una columna nueva en un DataFrame ya existente, simplemente se debe asignar un valor único o una Serie del mismo largo al nuevo nombre de columna:\n",
    "\n",
    "```\n",
    "df['new_column'] = valor_unico\n",
    "df['new_column'] = serie_del_mismo_largo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fuente'] = 'BCCH'\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo con fechas\n",
    "\n",
    "Pandas nos provee de herramientas para manipular fechas pero primero debemos decirle que una columna representa fechas.\n",
    "\n",
    "Para esto usamos el método ```pd.to_datetime()``` al que le debemos entregar la columna que contiene fechas y el formato de esas fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fecha'] = pd.to_datetime(df['Fecha'], format = '%d-%m-%y')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos nuestra columna con formato fecha, podemos ocupar los métodos de Pandas para trabajar con fechas usando el accesor ```.dt```. Por ejemplo, usaremos el método ```.dt.year``` para extraer el año de cada fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Año'] = df['Fecha'].dt.year\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, podemos aprovechar que creamos esta columna para ver cuántos datos por año tenemos usando el método ```value_counts()``` (esto lo pueden usar con cualquier columna, no es necesario que sea fecha):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Año'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agrupación de datos\n",
    "\n",
    "Si tenemos distintos grupos de datos sobre los que queremos trabajar en un mismo DataFrame, podemos ocupar el método ```groupby()``` para trabajar sobre cada grupo de datos por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de promedio anual de cada tipo de cambio\n",
    "df.groupby(by='Año').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imputación de Missings y Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrar de lleno en la imputación de missings y outliers, veamos gráficamente nuestras series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if \"/USD\" in column:\n",
    "        df.plot(x = 'Fecha', y=column, title=f\"Tipo de cambio {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al parecer solo hay missing values en la serie ARS/USD y que la serie CLP/USD tiene algunos outliers.\n",
    "\n",
    "Veamos ahora si es que tenemos más de un dato por fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fecha.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 2 datos para Febrero de 2024! Vamos a tener que trabajar eso también."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputación de Missings\n",
    "\n",
    "Partamos trabajando sobre los missings:\n",
    "\n",
    "Primero, veamos cuántos son y en qué fechas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # Aquí ocupamos el método isna() que nos devuelve valores booleanos indicando los datos nulos y\n",
    "                # luego los sumamos para obtener el total por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ARS/USD'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo tenemos 3 datos faltantes, entre junio y agosto de 2014.\n",
    "\n",
    "Para hacernos cargo de esto tenemos dos grandes opciones:\n",
    "\n",
    "- Eliminar las filas que tienen valores faltantes, lo que no es muy conveniente en el contexto de series de tiempo, pero sí puede ser muy útil cuando estén trabajando con otro tipo de datos.\n",
    "\n",
    "- Imputar los valores faltantes usando alguna técnica de las muchas que hay: forward filling, backward filling, usar el promedio (estas 3 primeras opciones las pueden lograr usando el método ```fillna()```), interpolar, hacer un forecast para esos datos usando los comportamientos estacionales de nuestra serie, etc.\n",
    "\n",
    "Por ahora, los vamos a llenar con una interpolación lineal simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARS/USD'] = df['ARS/USD'].interpolate()\n",
    "df.plot(x='Fecha', y='ARS/USD', title = \"Tipo de Cambio ARS/USD Interpolado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.Fecha >= '2014-05-01') & (df.Fecha <= '2014-09-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminación de duplicados\n",
    "\n",
    "Vamos a tratar ahora el problema de los datos duplicados para Febrero de 2024, veamos qué datos tenemos para esa fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Fecha'] == \"2024-02-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer solo fue un error en que se ingresó dos veces los mismos datos, podría haber sido peor si tuviésemos distintos valores para una misma fecha.\n",
    "\n",
    "Para arreglar esto usamos el método ```drop_duplicates()```. A él le podemos entregar el argumento ```keep = ...``` para decirle que mantenga el primero de nuestros datos duplicados (```\"first\"```), el último (```\"last\"```) o ninguno (```False```). Vamos a quedarnos con el primero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep = 'first')\n",
    "df[df['Fecha'] == \"2024-02-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputación de Outliers\n",
    "\n",
    "El análisis gráfico ya nos ayudó a identificar que solo en la serie CLP/USD tenemos outliers. Veamos más de cerca esta serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLP/USD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLP/USD'].sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLP/USD'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=[\"CLP/USD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estadísticas descriptivas nos muestran que tenemos un mínimo y un máximo muy alto para esta serie. Además, al mirar los datos ordenados de mayor a menor, de menor a mayor y el boxplot de la serie nos damos cuenta que solo son el mínimo y el máximo los valores atípicos.\n",
    "\n",
    "Para poder imputarlos, los reemplazaremos por un missing value y los trataremos igual que como tratamos los valores faltantes de la serie ARS/USD (por interpolación lineal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero identifiquemos las filas en que tenemos que imputar:\n",
    "df[df['CLP/USD'].isin([df['CLP/USD'].min(), df['CLP/USD'].max()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.loc[[177,193], 'CLP/USD'] = np.nan\n",
    "df.loc[[177,193], 'CLP/USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLP/USD'] = df['CLP/USD'].interpolate()\n",
    "df.plot(x='Fecha', y='CLP/USD', title = \"Tipo de Cambio CLP/USD Interpolado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[177,193], 'CLP/USD']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
